{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- http://iamtrask.github.io/2015/07/28/dropout/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.array([ [0,0,1],[0,1,1],[1,0,1],[1,1,1] ])\n",
    "y = np.array([[0,1,1,0]]).T\n",
    "alpha,hidden_dim,dropout_percent,do_dropout = (0.5,4,0.2,True)\n",
    "synapse_0 = 2*np.random.random((3,hidden_dim)) - 1\n",
    "synapse_1 = 2*np.random.random((hidden_dim,1)) - 1\n",
    "for j in xrange(60000):\n",
    "    layer_1 = (1/(1+np.exp(-(np.dot(X,synapse_0)))))\n",
    "    if(do_dropout):\n",
    "        layer_1 *= np.random.binomial([np.ones((len(X),hidden_dim))],1-dropout_percent)[0] * (1.0/(1-dropout_percent))\n",
    "    layer_2 = 1/(1+np.exp(-(np.dot(layer_1,synapse_1))))\n",
    "    layer_2_delta = (layer_2 - y)*(layer_2*(1-layer_2))\n",
    "    layer_1_delta = layer_2_delta.dot(synapse_1.T) * (layer_1 * (1-layer_1))\n",
    "    synapse_1 -= (alpha * layer_1.T.dot(layer_2_delta))\n",
    "    synapse_0 -= (alpha * X.T.dot(layer_1_delta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1_out = np.dot(inputs, W1) # (4, hidden_dim=3)\n",
    "layer1_activation = sigmoid(layer1_out)\n",
    "\n",
    "temp = np.ones(shape=(len(inputs), hidden_dim)) # ()\n",
    "dropout_mask = binomial([temp], 1-dropout_percent).squeeze() * (1.0/(1-dropout_percent))\n",
    "layer1_activation =* dropout_mask\n",
    "\n",
    "layer_2_out = np.dot(layer_1_activation, W2) # (4, 1)\n",
    "layer_2_activation = sigmoid(layer_2_out) # (4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.25, 1.25, 1.25],\n",
       "       [1.25, 0.  , 1.25],\n",
       "       [1.25, 1.25, 0.  ],\n",
       "       [0.  , 1.25, 0.  ]])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = x # (4, 2)\n",
    "layer_1_out = np.dot(inputs, W1) # (4, 3)\n",
    "layer_1_activation = sigmoid(layer_1_out) # (4, 3)\n",
    "layer_2_out = np.dot(layer_1_activation, W2) # (4, 1)\n",
    "layer_2_activation = sigmoid(layer_2_out) # (4, 1)\n",
    "\n",
    "loss = (y-layer_2_activation)**2\n",
    "if i%1000==0:\n",
    "    print(loss.mean())\n",
    "###### backprop\n",
    "layer_2_activation_delta = layer_2_activation - y # dL/dy_hat=d(y-y_hat)^2/dy_hat\n",
    "layer_2_out_delta = layer_2_activation_delta * sigmoid_output_to_derivative(layer_2_activation) # (4, 1)\n",
    "W2_gradient = np.dot(layer_1_activation.T, layer_2_out_delta) # (3, 1)\n",
    "\n",
    "layer_1_activation_delta = np.dot(layer_2_out_delta, W2.T) # (4, 3)\n",
    "layer_1_out_delta = layer_1_activation_delta * sigmoid_output_to_derivative(layer_1_activation) # (4, 3)\n",
    "W1_gradient = np.dot(inputs.T, layer_1_out_delta) # (2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# implement layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(output):\n",
    "    return output*(1-output)\n",
    "\n",
    "x = np.array([[0, 1],\n",
    "              [0, 0],\n",
    "              [1, 0],\n",
    "              [1, 1]])\n",
    "y = np.array([[1, 0, 1, 0]]).T\n",
    "\n",
    "np.random.seed(99)\n",
    "hidden_dim = 3\n",
    "W1 = np.random.random(size=(2, hidden_dim))\n",
    "W2 = np.random.random(size=(hidden_dim, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00030513188187812894\n",
      "0.00029084839348754356\n",
      "0.0002778352490411932\n",
      "0.0002659306008226012\n",
      "0.00025499893673764024\n",
      "0.00024492593781840144\n",
      "0.0002356144946975106\n",
      "0.00022698158948807824\n",
      "0.00021895583149047102\n",
      "0.00021147549224992553\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.7\n",
    "for i, iter_ in enumerate(range(10000)):\n",
    "    ###### forward\n",
    "    inputs = x # (4, 2)\n",
    "    layer_1_out = np.dot(inputs, W1) # (4, 3)\n",
    "    layer_1_activation = sigmoid(layer_1_out) # (4, 3)\n",
    "    layer_2_out = np.dot(layer_1_activation, W2) # (4, 1)\n",
    "    layer_2_activation = sigmoid(layer_2_out) # (4, 1)\n",
    "    \n",
    "    loss = (y-layer_2_activation)**2\n",
    "    if i%1000==0:\n",
    "        print(loss.mean())\n",
    "    ###### backprop\n",
    "    layer_2_activation_delta = layer_2_activation - y # dL/dy_hat=d(y-y_hat)^2/dy_hat\n",
    "    layer_2_out_delta = layer_2_activation_delta * sigmoid_output_to_derivative(layer_2_activation) # (4, 1)\n",
    "    W2_gradient = np.dot(layer_1_activation.T, layer_2_out_delta) # (3, 1)\n",
    "    \n",
    "    layer_1_activation_delta = np.dot(layer_2_out_delta, W2.T) # (4, 3)\n",
    "    layer_1_out_delta = layer_1_activation_delta * sigmoid_output_to_derivative(layer_1_activation) # (4, 3)\n",
    "    W1_gradient = np.dot(inputs.T, layer_1_out_delta) # (2, 3)\n",
    "    \n",
    "    ###### update weight\n",
    "    W2 -= alpha*W2_gradient\n",
    "    W1 -= alpha*W1_gradient"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
